{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8af803b-306b-4e2b-b3d1-80045aac2f2b",
   "metadata": {},
   "source": [
    "# Prepare Labelled Data\n",
    "\n",
    "This notebook prepares the labelled data to train the linear regression and neural network model to predict continuous sentiment scores based on word2vec and fasttext word embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf7ce97-1ada-469f-9233-1ca272f78442",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-29T10:42:58.618767Z",
     "iopub.status.busy": "2021-12-29T10:42:58.618250Z",
     "iopub.status.idle": "2021-12-29T10:42:58.625659Z",
     "shell.execute_reply": "2021-12-29T10:42:58.624339Z",
     "shell.execute_reply.started": "2021-12-29T10:42:58.618717Z"
    }
   },
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6039032a-6d5e-4ae3-aa27-12ce8cb7688e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:18:48.031745Z",
     "iopub.status.busy": "2022-01-02T20:18:48.031561Z",
     "iopub.status.idle": "2022-01-02T20:18:48.034702Z",
     "shell.execute_reply": "2022-01-02T20:18:48.034264Z",
     "shell.execute_reply.started": "2022-01-02T20:18:48.031729Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from gensim.models import KeyedVectors, FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71a1b53-f900-4770-b9b2-f4063143cb7e",
   "metadata": {},
   "source": [
    "### Sentiment Lexicon: Sentida2\n",
    "\n",
    "Below, the sentiment lexicon sentida2 is loaded and inspected. It was extracted from [Github](https://github.com/Guscode/Sentida2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decc2d36-3a77-4c0f-b6f8-de34aeb181bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:16:34.590769Z",
     "iopub.status.busy": "2022-01-01T15:16:34.589706Z",
     "iopub.status.idle": "2022-01-01T15:16:34.657699Z",
     "shell.execute_reply": "2022-01-01T15:16:34.657107Z",
     "shell.execute_reply.started": "2022-01-01T15:16:34.590718Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abe</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abort</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolut</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abstrakt</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absurd</td>\n",
       "      <td>-2.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word     score\n",
       "0       abe -1.000000\n",
       "1     abort -0.333333\n",
       "2   absolut  0.333333\n",
       "3  abstrakt  0.666667\n",
       "4    absurd -2.333333"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading sentiment lexicon\n",
    "sentiments = pd.read_csv(\"../../lexicons/sentida2_lexicon.csv\")\n",
    "# print the how many scores\n",
    "print(len(sentiments))\n",
    "sentiments[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521da350-3bbf-4a4b-a66e-07112a91bddd",
   "metadata": {},
   "source": [
    "### Word Embeddings: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3476892b-281c-48b4-9ba9-43d74d2dbef7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:17:03.583062Z",
     "iopub.status.busy": "2022-01-01T15:17:03.582395Z",
     "iopub.status.idle": "2022-01-01T15:17:11.957170Z",
     "shell.execute_reply": "2022-01-01T15:17:11.956134Z",
     "shell.execute_reply.started": "2022-01-01T15:17:03.583012Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load word2vec word embeddings\n",
    "word2vec = KeyedVectors.load_word2vec_format(\"../../embeddings/semantic_model_DAGW_cbow.wv.bin\", binary=True)\n",
    "# create emtpty dictionary\n",
    "w2v_dict = {}\n",
    "# put word2vec data into dictionary\n",
    "for idx, key in enumerate(word2vec.key_to_index):\n",
    "    w2v_dict[key] = word2vec[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f60ba98-3a17-401e-bebc-b623bd49268c",
   "metadata": {},
   "source": [
    "__Matching sentida2 sentiment scores with corresponding word embeddings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cf776bb-a101-4328-b383-8ff5d4c09d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:21:54.189032Z",
     "iopub.status.busy": "2022-01-01T15:21:54.188864Z",
     "iopub.status.idle": "2022-01-01T15:21:54.434868Z",
     "shell.execute_reply": "2022-01-01T15:21:54.434208Z",
     "shell.execute_reply.started": "2022-01-01T15:21:54.189014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = [] # empty list for embeddings\n",
    "X = [] # empty list for labels (sentiment scores)\n",
    "not_found = [] # empty list for word in sentida2 for which no embeddings could be found\n",
    "\n",
    "for index, row in sentiments.iterrows():\n",
    "    raw_word = row[\"word\"] # take the word\n",
    "    word = raw_word.lower() # lowercase the word\n",
    "    sent = row[\"score\"] # get the score\n",
    "    # if the word exist in word2vec, append to lists\n",
    "    if word in w2v_dict: \n",
    "        embed = w2v_dict[word]\n",
    "        y.append(sent)\n",
    "        X.append(embed)\n",
    "    # otherwise append to not found\n",
    "    else:\n",
    "        not_found.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00071de-9349-4952-b0c3-ff905dd0d97b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:28:03.297513Z",
     "iopub.status.busy": "2022-01-01T15:28:03.297375Z",
     "iopub.status.idle": "2022-01-01T15:28:03.301866Z",
     "shell.execute_reply": "2022-01-01T15:28:03.301310Z",
     "shell.execute_reply.started": "2022-01-01T15:28:03.297497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save not found words\n",
    "textfile = open(\"../../appendix/not_found_w2v_sentida2.txt\", \"w\")\n",
    "for element in not_found:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31c6f89e-715e-4cd3-b969-c2138ad27a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:27:25.304149Z",
     "iopub.status.busy": "2022-01-01T15:27:25.303997Z",
     "iopub.status.idle": "2022-01-01T15:27:25.308733Z",
     "shell.execute_reply": "2022-01-01T15:27:25.308195Z",
     "shell.execute_reply.started": "2022-01-01T15:27:25.304132Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "print(len(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aacbead4-4377-4da3-be8e-2ac6a0739fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:28:10.633382Z",
     "iopub.status.busy": "2022-01-01T15:28:10.633073Z",
     "iopub.status.idle": "2022-01-01T15:28:10.725153Z",
     "shell.execute_reply": "2022-01-01T15:28:10.723775Z",
     "shell.execute_reply.started": "2022-01-01T15:28:10.633366Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (6420, 300) ; Shape of y: (6420,)\n"
     ]
    }
   ],
   "source": [
    "# save X and y arrays\n",
    "X_array = np.array(X)\n",
    "y_array = np.array(y)\n",
    "\n",
    "print(\"Shape of X:\", X_array.shape, \"; Shape of y:\", y_array.shape)\n",
    "\n",
    "np.save(\"../../data/labelled_data/X_w2v_asent.npy\", X_array)\n",
    "np.save(\"../../data/labelled_data/y_w2v_asent.npy\", y_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f2cbe-47dc-468f-9cce-5d8f63faf51b",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1445a84-3d68-4227-ba17-d6745289b235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:22:18.676248Z",
     "iopub.status.busy": "2022-01-02T20:22:18.675633Z",
     "iopub.status.idle": "2022-01-02T20:24:59.829747Z",
     "shell.execute_reply": "2022-01-02T20:24:59.828988Z",
     "shell.execute_reply.started": "2022-01-02T20:22:18.676197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load fasttext embedding model\n",
    "ft_model = FastText.load(\"../../../../dagw_fasttext_embeddings/fasttext_model/fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef2ffdd-c262-4d87-8013-35337be79475",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:34:14.741544Z",
     "iopub.status.busy": "2022-01-02T20:34:14.741366Z",
     "iopub.status.idle": "2022-01-02T20:34:15.041457Z",
     "shell.execute_reply": "2022-01-02T20:34:15.040854Z",
     "shell.execute_reply.started": "2022-01-02T20:34:14.741526Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ft_y = [] # empty list for embeddings\n",
    "ft_X = [] # empty list for labels (sentiment scores)\n",
    "ft_not_found = [] # empty list of not founc\n",
    "\n",
    "for index, row in sentiments.iterrows():\n",
    "    raw_word = row[\"word\"]\n",
    "    word = raw_word.lower()\n",
    "    sent = row[\"score\"]\n",
    "    if word in ft_model.wv:\n",
    "        embed = ft_model.wv[word]\n",
    "        ft_y.append(sent)\n",
    "        ft_X.append(embed)\n",
    "    else:\n",
    "        ft_not_found.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "960ae3fe-6827-446f-a833-9bb90db2b94a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:34:35.524480Z",
     "iopub.status.busy": "2022-01-02T20:34:35.524335Z",
     "iopub.status.idle": "2022-01-02T20:34:35.528795Z",
     "shell.execute_reply": "2022-01-02T20:34:35.528359Z",
     "shell.execute_reply.started": "2022-01-02T20:34:35.524464Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ft_not_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bf8956f-dd02-4f10-970e-59df2c8017b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T12:46:40.332329Z",
     "iopub.status.busy": "2021-12-22T12:46:40.332175Z",
     "iopub.status.idle": "2021-12-22T12:46:40.529181Z",
     "shell.execute_reply": "2021-12-22T12:46:40.528231Z",
     "shell.execute_reply.started": "2021-12-22T12:46:40.332308Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (6592, 300) ; Shape of y: (6592,)\n"
     ]
    }
   ],
   "source": [
    "# save X and y arrays\n",
    "X_ft_array = np.array(ft_X)\n",
    "y_ft_array = np.array(ft_y)\n",
    "\n",
    "print(\"Shape of X:\", X_ft_array.shape, \"; Shape of y:\", y_ft_array.shape)\n",
    "\n",
    "np.save(\"../../data/labelled_data/X_ft_asent.npy\", X_ft_array)\n",
    "np.save(\"../../data/labelled_data/y_ft_asent.npy\", y_ft_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98525dc-3538-4246-b5ed-1675123b0af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-02T20:36:01.975445Z",
     "iopub.status.busy": "2022-01-02T20:36:01.975287Z",
     "iopub.status.idle": "2022-01-02T20:36:02.193237Z",
     "shell.execute_reply": "2022-01-02T20:36:02.192638Z",
     "shell.execute_reply.started": "2022-01-02T20:36:01.975429Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "# extra: some lemmas are not in the vocabulary of fasttext, but estimated using the trained-subwords, here we find them\n",
    "in_ft_voc=[]\n",
    "\n",
    "for index, row in sentiments.iterrows():\n",
    "    raw_word = row[\"word\"]\n",
    "    word = raw_word.lower()\n",
    "    if word in ft_model.wv.key_to_index:\n",
    "        in_ft_voc.append(index)\n",
    "        \n",
    "print(len(in_ft_voc)) # those are in the vocabulary\n",
    "print(6592-len(in_ft_voc)) # those are not in the vocabulary, but estimated from subword embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
