{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abaadd66-6aab-4bc7-a98d-f00cd981b337",
   "metadata": {},
   "source": [
    "# Prepare Unlabelled Data for Lexicon Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b4a3c-9c37-4807-b2b6-d9cde30153c0",
   "metadata": {},
   "source": [
    "This script prepares the unlabelled data of lemmas and their corresponding word2vec and fastText embeddings, which will be used for lexicon expansion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03793d-6cea-4351-a8a8-121eded007eb",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbea61c2-de9f-46e7-9923-a0aba3c86a3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:06:43.208076Z",
     "iopub.status.busy": "2022-01-01T15:06:43.207558Z",
     "iopub.status.idle": "2022-01-01T15:06:44.166834Z",
     "shell.execute_reply": "2022-01-01T15:06:44.166208Z",
     "shell.execute_reply.started": "2022-01-01T15:06:43.208023Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors, FastText\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3f2438-497b-4ae8-bcfd-26208276f8a3",
   "metadata": {},
   "source": [
    "### Prepare list of frequent lemmas (10000-20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5d0b635-486c-40b2-9c1d-b71c5db0a03f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:07:26.780804Z",
     "iopub.status.busy": "2022-01-01T15:07:26.780304Z",
     "iopub.status.idle": "2022-01-01T15:07:27.023763Z",
     "shell.execute_reply": "2022-01-01T15:07:27.022940Z",
     "shell.execute_reply.started": "2022-01-01T15:07:26.780754Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load lemmas\n",
    "lemmas = pd.read_csv('../../lemmas/lemma-30k-2017.txt', sep = \"\\t\", header = None)\n",
    "lemmas = lemmas.rename(columns={0: \"POS\", 1: \"word\", 2: \"freq\"})\n",
    "lemmas = lemmas.sort_values([\"freq\"], ascending = False)\n",
    "lemmas = lemmas[10000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb8ae1d-d2eb-4c81-a4ed-7e61fe15025f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:07:28.358064Z",
     "iopub.status.busy": "2022-01-01T15:07:28.357576Z",
     "iopub.status.idle": "2022-01-01T15:07:28.374709Z",
     "shell.execute_reply": "2022-01-01T15:07:28.374138Z",
     "shell.execute_reply.started": "2022-01-01T15:07:28.358014Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>NC</td>\n",
       "      <td>slankekur</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>A</td>\n",
       "      <td>autoriseret</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>V</td>\n",
       "      <td>falme</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>NC</td>\n",
       "      <td>smørrebrød</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>NC</td>\n",
       "      <td>øjekast</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19993</th>\n",
       "      <td>I</td>\n",
       "      <td>jovist</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19992</th>\n",
       "      <td>V</td>\n",
       "      <td>gennemprøve</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19991</th>\n",
       "      <td>NC</td>\n",
       "      <td>erstatningsansvar</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19990</th>\n",
       "      <td>NC</td>\n",
       "      <td>brændselscelle</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004</th>\n",
       "      <td>NC</td>\n",
       "      <td>møbelarkitekt</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      POS               word      freq\n",
       "10000  NC          slankekur  0.000004\n",
       "10001   A        autoriseret  0.000004\n",
       "10002   V              falme  0.000004\n",
       "10003  NC         smørrebrød  0.000004\n",
       "10004  NC            øjekast  0.000004\n",
       "...    ..                ...       ...\n",
       "19993   I             jovist  0.000001\n",
       "19992   V        gennemprøve  0.000001\n",
       "19991  NC  erstatningsansvar  0.000001\n",
       "19990  NC     brændselscelle  0.000001\n",
       "20004  NC      møbelarkitekt  0.000001\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e902f3d0-a5d0-449a-a80b-f29a6d835383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:08:02.792500Z",
     "iopub.status.busy": "2022-01-01T15:08:02.791863Z",
     "iopub.status.idle": "2022-01-01T15:08:02.803265Z",
     "shell.execute_reply": "2022-01-01T15:08:02.802529Z",
     "shell.execute_reply.started": "2022-01-01T15:08:02.792448Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9937"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep relevant pos tags\n",
    "pos_tags = [\"A\", \"D\", \"NC\", \"V\", \"I\"]\n",
    "lemmas_relevant = lemmas[lemmas['POS'].isin(pos_tags)]\n",
    "len(lemmas_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a968387-af64-46be-8f01-2a3daf4ffd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:08:20.829494Z",
     "iopub.status.busy": "2022-01-01T15:08:20.828851Z",
     "iopub.status.idle": "2022-01-01T15:08:20.872597Z",
     "shell.execute_reply": "2022-01-01T15:08:20.871841Z",
     "shell.execute_reply.started": "2022-01-01T15:08:20.829442Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592\n"
     ]
    }
   ],
   "source": [
    "# load sentida2 base lexicon\n",
    "sentiments = pd.read_csv(\"../../lexicons/sentida2_lexicon.csv\")\n",
    "print(len(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafb1690-ec53-45cf-8da9-f5045304270f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:08:21.168316Z",
     "iopub.status.busy": "2022-01-01T15:08:21.167864Z",
     "iopub.status.idle": "2022-01-01T15:08:21.182217Z",
     "shell.execute_reply": "2022-01-01T15:08:21.181499Z",
     "shell.execute_reply.started": "2022-01-01T15:08:21.168267Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9349"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lemmas without that don't have a sentiment score already\n",
    "lemmas_nosent = lemmas_relevant[~lemmas_relevant['word'].isin(sentiments[\"word\"].tolist())]\n",
    "len(lemmas_nosent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5dff9-d069-47ca-900f-6b9b87e7dd81",
   "metadata": {},
   "source": [
    "### Match with word2vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f0f4d7-cbfa-49f7-b083-c98121adb5dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:09:04.660481Z",
     "iopub.status.busy": "2022-01-01T15:09:04.659971Z",
     "iopub.status.idle": "2022-01-01T15:09:17.301249Z",
     "shell.execute_reply": "2022-01-01T15:09:17.299662Z",
     "shell.execute_reply.started": "2022-01-01T15:09:04.660430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load word embeddings and save to dictionary\n",
    "word2vec = KeyedVectors.load_word2vec_format(\"../../embeddings/semantic_model_DAGW_cbow.wv.bin\", binary=True)\n",
    "w2v_dict = dict({})\n",
    "for idx, key in enumerate(word2vec.key_to_index):\n",
    "    w2v_dict[key] = word2vec[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "638fccb3-a75a-4eb5-b67c-b68eb6da9937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:12:29.820725Z",
     "iopub.status.busy": "2022-01-01T15:12:29.820550Z",
     "iopub.status.idle": "2022-01-01T15:12:30.112686Z",
     "shell.execute_reply": "2022-01-01T15:12:30.112151Z",
     "shell.execute_reply.started": "2022-01-01T15:12:29.820703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find embeddings for lemmas with which we want to extend the dictionary\n",
    "embeddings_to_predict = []\n",
    "words_to_predict = []\n",
    "\n",
    "for idx, row in lemmas_nosent.iterrows():\n",
    "    # get word from lemma df\n",
    "    word = row[\"word\"]\n",
    "    # get embedding of corresponding word\n",
    "    if word in w2v_dict:\n",
    "        embedding = w2v_dict[word]\n",
    "        # append word to word list\n",
    "        words_to_predict.append(word)\n",
    "        # append embedding to embedding list\n",
    "        embeddings_to_predict.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f70a627-525f-490b-8306-2d0e6a62cd6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:14:58.359359Z",
     "iopub.status.busy": "2022-01-01T15:14:58.359139Z",
     "iopub.status.idle": "2022-01-01T15:14:58.409153Z",
     "shell.execute_reply": "2022-01-01T15:14:58.408389Z",
     "shell.execute_reply.started": "2022-01-01T15:14:58.359339Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8639, 300) (8639,)\n"
     ]
    }
   ],
   "source": [
    "# save the embeddings and word to predict to numpy arrays\n",
    "embeddings_array = np.array(embeddings_to_predict)\n",
    "words_array = np.array(words_to_predict)\n",
    "\n",
    "print(embeddings_array.shape, words_array.shape)\n",
    "\n",
    "np.save(\"../../data/unlabelled_data/w2v_embeds_to_predict.npy\", embeddings_array)\n",
    "np.save(\"../../data/unlabelled_data/w2v_words_to_predict.npy\", words_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f338632-a824-44ad-bf37-a85bc45da6c8",
   "metadata": {},
   "source": [
    "### Match with fastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d178bbd-ac5e-408c-8353-a10c364882e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:15:28.092782Z",
     "iopub.status.busy": "2022-01-01T15:15:28.092634Z",
     "iopub.status.idle": "2022-01-01T15:18:01.956637Z",
     "shell.execute_reply": "2022-01-01T15:18:01.955752Z",
     "shell.execute_reply.started": "2022-01-01T15:15:28.092765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load fastText model\n",
    "ft_model = FastText.load(\"../../../../dagw_fasttext_embeddings/fasttext_model/fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cb8cde7-fb73-41e3-9525-9b462d8c88a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:35:09.139463Z",
     "iopub.status.busy": "2022-01-01T15:35:09.139311Z",
     "iopub.status.idle": "2022-01-01T15:35:09.477713Z",
     "shell.execute_reply": "2022-01-01T15:35:09.476906Z",
     "shell.execute_reply.started": "2022-01-01T15:35:09.139445Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find embeddings for lemmas with which we want to extend the dictionary\n",
    "embeddings_to_predict_ft = []\n",
    "words_to_predict_ft = []\n",
    "\n",
    "for idx, row in lemmas_nosent.iterrows():\n",
    "    # get word from lemma df\n",
    "    word = row[\"word\"]\n",
    "    # get embedding of corresponding word\n",
    "    if word in ft_model.wv:\n",
    "        embedding = ft_model.wv[word]\n",
    "        # append word to word list\n",
    "        words_to_predict_ft.append(word)\n",
    "        # append embedding to embedding list\n",
    "        embeddings_to_predict_ft.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ad5170c-1d6e-49d1-b03e-8ed0eb8e4d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:39:09.832681Z",
     "iopub.status.busy": "2022-01-01T15:39:09.832535Z",
     "iopub.status.idle": "2022-01-01T15:39:09.872598Z",
     "shell.execute_reply": "2022-01-01T15:39:09.871726Z",
     "shell.execute_reply.started": "2022-01-01T15:39:09.832665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9349, 300) (9349,)\n"
     ]
    }
   ],
   "source": [
    "# save the embeddings and word to predict to numpy arrays\n",
    "embeddings_array_ft = np.array(embeddings_to_predict_ft)\n",
    "words_array_ft = np.array(words_to_predict_ft)\n",
    "\n",
    "print(embeddings_array_ft.shape, words_array_ft.shape)\n",
    "\n",
    "np.save(\"../../data/unlabelled_data/ft_embeds_to_predict.npy\", embeddings_array_ft)\n",
    "np.save(\"../../data/unlabelled_data/ft_words_to_predict.npy\", words_array_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c45c5169-34df-46ab-a974-273a82f46044",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-01T15:49:33.281032Z",
     "iopub.status.busy": "2022-01-01T15:49:33.280429Z",
     "iopub.status.idle": "2022-01-01T15:49:33.496410Z",
     "shell.execute_reply": "2022-01-01T15:49:33.495839Z",
     "shell.execute_reply.started": "2022-01-01T15:49:33.280968Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500\n",
      "2849\n"
     ]
    }
   ],
   "source": [
    "# extra: some lemmas are not in the vocabulary of fasttext, but estimated using the trained-subwords, here we find them\n",
    "in_ft_voc=[]\n",
    "\n",
    "for index, row in sentiments.iterrows():\n",
    "    raw_word = row[\"word\"]\n",
    "    word = raw_word.lower()\n",
    "    if word in ft_model.wv.key_to_index:\n",
    "        in_ft_voc.append(index)\n",
    "        \n",
    "print(len(in_ft_voc)) # those are in the vocabulary\n",
    "print(9349-len(in_ft_voc)) # those are not in the vocabulary, but estimated from subword embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
