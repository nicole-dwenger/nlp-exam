
Run from 2021-12-22 13:50:34.742609
Results of Grid Search for linear_regression and word2vec:
Order of Params: optimizer, learning_rate, batch_size, epochs, hidden_layers, activation

('adam', 0.001, 10, 50)
train_loss: 0.8907768726348877, val_loss: 0.8829899430274963

('adam', 0.001, 10, 100)
train_loss: 0.8895425200462341, val_loss: 0.8904235363006592

('adam', 0.001, 10, 150)
train_loss: 0.8871650695800781, val_loss: 0.8912495970726013

('adam', 0.001, 10, 200)
train_loss: 0.8914657235145569, val_loss: 0.8891116380691528

('adam', 0.001, 50, 50)
train_loss: 0.8730337619781494, val_loss: 0.8833909630775452

('adam', 0.001, 50, 100)
train_loss: 0.8682910799980164, val_loss: 0.8856704235076904

('adam', 0.001, 50, 150)
train_loss: 0.8697411417961121, val_loss: 0.8793710470199585

('adam', 0.001, 50, 200)
train_loss: 0.8694841861724854, val_loss: 0.8819315433502197

('adam', 0.001, 100, 50)
train_loss: 0.865684449672699, val_loss: 0.8879886269569397

('adam', 0.001, 100, 100)
train_loss: 0.8671510815620422, val_loss: 0.8857736587524414

('adam', 0.001, 100, 150)
train_loss: 0.8645708560943604, val_loss: 0.8864916563034058

('adam', 0.001, 100, 200)
train_loss: 0.8658899068832397, val_loss: 0.8813261389732361

('adam', 0.01, 10, 50)
train_loss: 1.1727958917617798, val_loss: 1.0990135669708252

('adam', 0.01, 10, 100)
train_loss: 1.1797245740890503, val_loss: 1.1005910634994507

('adam', 0.01, 10, 150)
train_loss: 1.1457802057266235, val_loss: 1.139304518699646

('adam', 0.01, 10, 200)
train_loss: 1.1820590496063232, val_loss: 1.060363531112671

('adam', 0.01, 50, 50)
train_loss: 0.9982526302337646, val_loss: 0.9277598857879639

('adam', 0.01, 50, 100)
train_loss: 0.9958898425102234, val_loss: 0.9835553765296936

('adam', 0.01, 50, 150)
train_loss: 0.9960733652114868, val_loss: 0.9387132525444031

('adam', 0.01, 50, 200)
train_loss: 0.9812610745429993, val_loss: 0.9273616671562195

('adam', 0.01, 100, 50)
train_loss: 0.9486372470855713, val_loss: 0.9166464805603027

('adam', 0.01, 100, 100)
train_loss: 0.9564508199691772, val_loss: 0.957226574420929

('adam', 0.01, 100, 150)
train_loss: 0.942776620388031, val_loss: 0.9468714594841003

('adam', 0.01, 100, 200)
train_loss: 0.9621337652206421, val_loss: 0.9324153065681458

('sgd', 0.001, 10, 50)
train_loss: 0.8675259947776794, val_loss: 0.8918890357017517

('sgd', 0.001, 10, 100)
train_loss: 0.8681814670562744, val_loss: 0.8868299722671509

('sgd', 0.001, 10, 150)
train_loss: 0.8672748804092407, val_loss: 0.8833926320075989

('sgd', 0.001, 10, 200)
train_loss: 0.8672016263008118, val_loss: 0.8877673745155334

('sgd', 0.001, 50, 50)
train_loss: 0.8940829634666443, val_loss: 0.8923267126083374

('sgd', 0.001, 50, 100)
train_loss: 0.8670360445976257, val_loss: 0.8867777585983276

('sgd', 0.001, 50, 150)
train_loss: 0.8599287271499634, val_loss: 0.8811383247375488

('sgd', 0.001, 50, 200)
train_loss: 0.8590246438980103, val_loss: 0.8896482586860657

('sgd', 0.001, 100, 50)
train_loss: 0.9764753580093384, val_loss: 0.9768567681312561

('sgd', 0.001, 100, 100)
train_loss: 0.8945282697677612, val_loss: 0.9065635800361633

('sgd', 0.001, 100, 150)
train_loss: 0.8707773685455322, val_loss: 0.8979137539863586

('sgd', 0.001, 100, 200)
train_loss: 0.8623775839805603, val_loss: 0.8846526145935059

('sgd', 0.01, 10, 50)
train_loss: 0.9581782221794128, val_loss: 0.9424470067024231

('sgd', 0.01, 10, 100)
train_loss: 0.9598205089569092, val_loss: 0.9217655658721924

('sgd', 0.01, 10, 150)
train_loss: 0.9545987248420715, val_loss: 0.9584870934486389

('sgd', 0.01, 10, 200)
train_loss: 0.9568743705749512, val_loss: 0.9259781837463379

('sgd', 0.01, 50, 50)
train_loss: 0.8815051317214966, val_loss: 0.8869341015815735

('sgd', 0.01, 50, 100)
train_loss: 0.8799293041229248, val_loss: 0.8927725553512573

('sgd', 0.01, 50, 150)
train_loss: 0.8803274035453796, val_loss: 0.8872677683830261

('sgd', 0.01, 50, 200)
train_loss: 0.8796324729919434, val_loss: 0.906265377998352

('sgd', 0.01, 100, 50)
train_loss: 0.8702110052108765, val_loss: 0.8994308114051819

('sgd', 0.01, 100, 100)
train_loss: 0.8688900470733643, val_loss: 0.8893041014671326

('sgd', 0.01, 100, 150)
train_loss: 0.8689993619918823, val_loss: 0.8853534460067749

('sgd', 0.01, 100, 200)
train_loss: 0.8705587983131409, val_loss: 0.8877114653587341


---------
BEST MODEL
('adam', 0.001, 50, 150)
val_loss: 0.8793710470199585
---------
